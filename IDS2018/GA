# -*- coding: utf-8 -*-
"""
Created on Wed Jul 20 16:36:32 2022

@author: Ahmed El_Shamy
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score ,confusion_matrix, classification_report
from sklearn.metrics import precision_score, recall_score
import matplotlib.pyplot as plt
import seaborn as sns
# from sklearn.model_selection import RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from scipy.stats import randint as sp_randint
from evolutionary_search import EvolutionaryAlgorithmSearchCV
from sklearn_genetic import GASearchCV


# Display Setting
pd.options.display.max_columns= 90
pd.options.display.max_rows= 100

df = pd.read_csv('C:/final/ids2017/dataset/data1.csv')

df.shape
df.dtypes
df['label'].value_counts()

df.head()

X = df.drop(['label'], axis=1)
X

y = df['label']
y

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)


clf1 = DecisionTreeClassifier()




n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
# Number of features to consider at every split
max_features = ['auto', 'sqrt','log2']
# Maximum number of levels in tree
max_depth = [int(x) for x in np.linspace(10, 1000,10)]
# Minimum number of samples required to split a node
min_samples_split = [2, 5, 10,14]
# Minimum number of samples required at each leaf node
min_samples_leaf = [1, 2, 4,6,8]
# Create the random grid
param = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
              'criterion':['entropy','gini']}








parameters_to_tune = {'min_samples_split': Integer(2,  6),
                      'min_samples_leaf': Integer(1,  4),
                      'max_depth': Integer(4, 15],
                      'splitter' : Categorical('best', 'random'),
                      'max_features': Integer[2, 6],
                      'class_weight':[{0:0.1, 1:1, 2:1, 3:1, 4:1, 5:1, 6:1, 7:1, 8:1, 9:1, 10:1, 12:1, 13:1, 14:1 },
                                 {0:0.2, 1:0.9, 2:0.9, 3:0.9, 4:0.9, 5:0.9, 6:0.9, 7:0.9, 8:0.9, 9:1, 10:1, 12:1, 13:1, 14:1 },
                                 {0:0.3, 1:0.6, 2:0.6, 3:0.6, 4:0.6, 5:0.7, 6:0.7, 7:0.8, 8:0.8, 9:0.8, 10:1, 12:1, 13:1, 14:1 }]
                      }
                          


clf = volutionaryAlgorithmSearchCV(estimator = clf1, params = parameters_to_tune, population_size=50, gene_mutation_prob=0.10,
                                   gene_crossover_prob=0.5, tournament_size=3, generations_number=5, n_jobs=4)
clf.fit(x_train, y_train)



clf.best_params_
clf.best_score_
clf.best_estimator_


# report the best configuration
print("Best: %f using %s" % (clf.best_score_, clf.best_params_))
# report all configurations
means = clf.cv_results_['mean_test_score']
means
stds = clf.cv_results_['std_test_score']
params = clf.cv_results_['params']
params

for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))
    

# using Optimized Parameter Obtained from GridSearchCV 
weights = {0:0.3, 1:0.6, 2:0.6, 3:0.6, 4:0.6, 5:0.7, 6:0.7, 7:0.8, 8:0.8, 9:0.8, 10:1.0, 12:1.0, 13:1.0, 14:1.0 }

    
clf1 = DecisionTreeClassifier()
clf=AdaBoostClassifier(random_state=96,  base_estimator=DecisionTreeClassifier(splitter='best', max_depth= 15, max_features = 6, min_samples_leaf =1, min_samples_split = 6, class_weight=weights), n_estimators=100,learning_rate=0.01, algorithm='SAMME.R')

clf.fit(x_train, y_train)  
y_pred = clf.predict(x_test)



# Confusion Matrix
matrix = confusion_matrix(y_test, y_pred)                                  
matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]


# Plot
plt.figure(figsize=(20,20))
sns.set(font_scale=1.4)
sns.heatmap(matrix, annot=True, annot_kws={'size':10},cmap=plt.cm.Greens, linewidths=0.2)

# Classification Report
print(classification_report(y_test, y_pred))



# G-mean

precision = precision_score(y_test, y_pred, average='micro')
recall = recall_score(y_test, y_pred, average='micro')
#parameter 'micro' calculates metrics globally by counting the total TP, FN and FP

scores = [precision, recall]
weights = [0.5,0.5]  #60% precision, 40% recall

# weighted Geometric Mean
    wgm = np.product(np.power(scores, weights))
    wgm
