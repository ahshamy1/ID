# -*- coding: utf-8 -*-
"""
Created on Tue Jul 19 21:12:42 2022

@author: Ahmed  EL_Shamy
"""

# import important packages
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import pandas_profiling
from matplotlib import rcParams
import warnings
warnings.filterwarnings("ignore")

# figure size in inches
rcParams["figure.figsize"] = 10, 6
np.random.seed(42)

# Load dataset
df = pd.read_csv('C:/final/ids2017/dataset/data1.csv')

df['label'].value_counts()
df.info
df.describe()
# show sample of the dataset
df.sample(5)

# show columns
df.columns

# split data into input and taget variable(s)
X = df.drop("label", axis=1)
y = df["label"]

# standardize the dataset
# scaler = StandardScaler()
# X_scaled = scaler.fit_transform(X)


# split into train and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.20, random_state=42)





# create the classifier
classifier = RandomForestClassifier(n_estimators=100)

# Train the model using the training sets
classifier.fit(X_train, y_train)


# predictin on the test set
y_pred = classifier.predict(X_test)


# Calculate Model Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))

# check Important features
feature_importances_df = pd.DataFrame(
    {"feature": list(X.columns), "importance": classifier.feature_importances_}
).sort_values("importance", ascending=False)

# Display
feature_importances_df

# visualize important featuers & Creating a bar plot
sns.barplot(x=feature_importances_df.feature, y=feature_importances_df.importance)

# Add labels to your

plt.xlabel("Feature Importance Score")
plt.ylabel("Features")
plt.title("Visualizing Important Features")
plt.xticks(
    rotation=45, horizontalalignment="right", fontweight="light", fontsize="x-large"
)
plt.show()

# load data with selected features
X = df.drop(["label", "fin_flag_count", "idle_min", "bwd_packet_length_min", "idle_mean", "idle_max", "ack_flag_count" ], axis=1)
y = df["label"]

# # standardize the dataset
# scaler = StandardScaler()
# X_scaled = scaler.fit_transform(X)

# split into train and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.20, random_state=42)

# create the classifier
classifier = RandomForestClassifier(n_estimators=100)

# Train the model using the training sets
classifier.fit(X_train, y_train)


# predictin on the test set
y_pred = classifier.predict(X_test)


# Calculate Model Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))
